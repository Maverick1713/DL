ADALINE::::



import numpy as np

def Adaline(Input, Target, lr=0.2, stop=0.001):
    weight = np.random.random(Input.shape[1])
    bias = np.random.random(1)[0]  # Extract scalar from array

    Error = [stop + 1]
    # Check the stop condition for the network
    while Error[-1] > stop or Error[-1] - Error[-2] > 0.0001:
        error = []
        for i in range(Input.shape[0]):
            Y_input = np.dot(weight, Input[i]) + bias

            # Update the weight
            for j in range(Input.shape[1]):
                weight[j] += lr * (Target[i] - Y_input) * Input[i][j]

            # Update the bias
            bias = bias + lr * (Target[i] - Y_input)

            # Store squared error value
            error.append((Target[i] - Y_input) ** 2)

        # Store sum of squared errors
        Error.append(sum(error))

    return weight, bias

# Input dataset
x = np.array([[1.0, 1.0, 1.0],
              [1.0, -1.0, 1.0],
              [-1.0, 1.0, 1.0],
              [-1.0, -1.0, -1.0]])

# Target values
t = np.array([1, 1, 1, -1])

# Train the Adaline model
w, b = Adaline(x, t, lr=0.2, stop=0.001)

# Print the final weights and bias
print('Weights:', w)
print('Bias:', b)

# Predict outputs
predicted_outputs = []
for i in range(x.shape[0]):
    predicted_output = np.dot(w, x[i]) + b
    predicted_outputs.append(predicted_output)

# Display inputs and predicted outputs
for i in range(x.shape[0]):
    print("Input:", x[i][0], x[i][1], "Output:", predicted_outputs[i])





MADALINE:::

import numpy as np

# Activation function
def activation_fn(z):
    return 1 if z >= 0 else -1

def Madaline(Input, Target, lr, epoch):
    weight = np.random.random((Input.shape[1], Input.shape[1]))
    bias = np.random.random(Input.shape[1])
    w = np.array([0.5 for _ in range(weight.shape[1])])
    b = 0.5
    k = 0
    while k < epoch:
        error = []
        z_input = np.zeros(bias.shape[0])
        z = np.zeros(bias.shape[0])
        for i in range(Input.shape[0]):
            for j in range(Input.shape[1]):
                z_input[j] = sum(weight[j] * Input[i]) + bias[j]
                z[j] = activation_fn(z_input[j])

            y_input = sum(z * w) + b
            y = activation_fn(y_input)

            # Update the weight & bias
            if y != Target[i]:
                for j in range(weight.shape[1]):
                    weight[j] = weight[j] + lr * (Target[i] - z_input[j]) * Input[i][j]
                    bias[j] = bias[j] + lr * (Target[i] - z_input[j])

            # Store squared error value
            error.append((Target[i] - y_input) ** 2)

        # Compute sum of square error
        Error = sum(error)
        k += 1

    return weight, bias

# Prediction function
def prediction(X, w, b):
    y = []
    for i in range(X.shape[0]):
        x = X[i]
        z1 = x * w
        z_1 = []
        for j in range(z1.shape[1]):
            z_1.append(activation_fn(sum(z1[j]) + b[j]))
        y_in = sum(np.array(z_1) * np.array([0.5 for _ in range(w.shape[1])])) + 0.5
        y.append(activation_fn(y_in))
    return y

# Input dataset
x = np.array([[1.0, 1.0, 1.0],
              [1.0, -1.0, 1.0],
              [-1.0, 1.0, 1.0],
              [-1.0, -1.0, -1.0]])

# Target values
t = np.array([1, 1, 1, -1])

# Train the MADALINE model
w, b = Madaline(x, t, lr=0.0001, epoch=3)

# Print the final weights and bias
print('Weights:', w)
print('Bias:', b)

# Predict outputs
predicted_outputs = prediction(x, w, b)

# Display inputs and predicted outputs
for i in range(x.shape[0]):
    print("Input:", x[i][0], x[i][1], "Output:", predicted_outputs[i])





